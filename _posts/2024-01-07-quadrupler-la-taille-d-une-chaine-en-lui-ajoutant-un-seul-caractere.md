---
author: Nico
date: 2024-01-07 12:00:00+01:00
image:
    feature: null
lang: fr
layout: page
published: false
redirect_from: []
tags: []
title: Comment quadrupler la taille dâ€™une chaine en lui ajoutant un seul caractÃ¨reÂ ?
---

Dans cet article, nous allons dÃ©couvrir quelques subtilitÃ©s des chaines de caractÃ¨res en Python et en UTF-8.

ParticuliÃ¨rementÂ :

-   Quâ€™il est possible de quadrupler la mÃ©moire nÃ©cessaire Ã  une chaine en ne lui ajoutant quâ€™un seul caractÃ¨re.
-   Que cela est dÃ» au fait quâ€™en Python la taille des caractÃ¨res dâ€™une chaine est fixe, alors quâ€™UTF-8 utilise une taille de caractÃ¨res variable.
-   Quâ€™il est possible de compter super rapidement le nombre de caractÃ¨res en fonction de leur taille en octet dans une string codÃ©e en UTF-8.

> N.B. Dans cet article, quand il est fait mention de Python, il sâ€™agit toujours de PythonÂ 3, jamais de PythonÂ 2.

Les versions utilisÃ©es pour les tests sontÂ :

-   Python 3.11.6
-   Python 3.12.1

Lâ€™OS est macOS Sonoma 14.2.1 et les interprÃ©teurs Python ont Ã©tÃ© installÃ©s avec [Homebrew].

[Homebrew]: https://brew.sh/

Lâ€™idÃ©e mâ€™est venue dâ€™Ã©crire cet article suite Ã  [une question sur Stackoverflow] concernant la comparaison entre la taille dâ€™une chaine de caractÃ¨res en mÃ©moire avec Python avec sa taille quand elle est enregistrÃ©e dans un fichierÂ UTF-8.

[une question sur Stackoverflow]: https://stackoverflow.com/q/77310610/3057377

Lâ€™auteur sâ€™Ã©tonne que la taille en mÃ©moire soit 4Â fois plus grande que celle sur disque.
Mais est-ce si surprenantÂ ?
Voyons cela dâ€™un peu plus prÃ¨s.

## DiffÃ©rences de tailles

Il faut dâ€™abord savoir que Python enregistre les chaines avec des caractÃ¨res codÃ©s sur 1, 2 ou 4Â octets, mais tous les caractÃ¨res dâ€™une mÃªme chaine doivent Ãªtre codÃ©s avec le mÃªme nombre dâ€™octets.
Câ€™est â€œlâ€™encodage Ã  taille fixeâ€ ou _â€œfixed-width encodingâ€_ en anglais.

En UTF-8, les choses sont un peu diffÃ©rentes, les caractÃ¨res dâ€™une chaine sont stockÃ©s sur 1, 2, 3 ou 4Â octets, mais il est possible dâ€™utiliser des caractÃ¨res codÃ©s avec des nombres diffÃ©rents dâ€™octets dans la mÃªme chaine.
Câ€™est â€œlâ€™encodage Ã  taille variableâ€, ou _â€œvariable-width encodingâ€_ en anglais.

Cette diffÃ©rence entre taille fixe et taille variable a une consÃ©quence intÃ©ressanteÂ :
Il est possible de quadrupler la taille dâ€™une chaine en mÃ©moire en lui ajoutant un seul caractÃ¨re.
Voici comment.

## Cas oÃ¹ la taille est (presque) identique en Python et UTF-8

Tout dâ€™abord, crÃ©ons une chaine contenant 1000Â fois le mÃªme caractÃ¨re codÃ© sur 1Â octet, par exemple le caractÃ¨re `A` (`chr(65)`) et regardons la taille du rÃ©sultat.

```python
import os
import sys

print("# chaine                         : 1000 * chr(65)")
s1 = 1000 * chr(65)
print(f"taille de la chaine python (RAM) : {sys.getsizeof(s1)} octets")
# 1049 avec Python 3.11
# 1041 avec Python 3.12
```

On voit que cette chaine fait un peu plus que 1000Â octets.
Les octets supplÃ©mentaires sont utilisÃ©s pour enregistrer des mÃ©tadonnÃ©es, mais laissons Ã§a de cÃ´tÃ© pour lâ€™instant.

Convertissons maintenant cette chaine en sa reprÃ©sentationÂ UTF-8.

```python
s1u = s1.encode("utf-8")
print(f"taille de la chaine utf-8 (RAM)  : {sys.getsizeof(s1u)} octets")
# 1033 Python 3.11 et 3.12
```

On constate que la taille de la chaÃ®ne codÃ©e en UTF-8 et stockÃ©e en mÃ©moire vive est dâ€™environ 1000Â octets.
Comme pour la chaine prÃ©cÃ©dente, Python ajoute quelques octets pour les mÃ©tadonnÃ©es.

Convertissons une deuxiÃ¨me fois cette chaÃ®ne, enregistrons-la sur le disque.

```python
fname = "s1u.txt"
with open(file=fname, mode="wt", encoding="utf-8") as _f:
    _f.write(s1)
print(f"taille de la chaine utf-8 (HD)   : {os.path.getsize(fname)} octets")
# 1000 Python 3.11 et 3.12
```

On constate que la taille de la chaÃ®ne codÃ©e en UTF-8 et stockÃ©e sur un disque dur est exactement 1000Â octets.

ConclusionÂ : si on nÃ©glige la place prise par les mÃ©tadonnÃ©es qui ne dÃ©pend pas de la taille de la chaine, on voit quâ€™une chaine qui ne contient que le caractÃ¨re `A` Ã  la mÃªme taille dans les trois casÂ : 1.Â en mÃ©moire au format Python, 2.Â en mÃ©moire au format UTF-8, 3.Â sur un disque au format UTF-8.

Voyant maintenant les cas oÃ¹ cette Ã©galitÃ© nâ€™est plus vraie.

## Quadruplons la taille de la chaine Python

Ajoutons le caractÃ¨re `ğŸ˜ˆ` (`chr(128520)`) codÃ© sur 4Â octets Ã  notre chaine initiale et regardons quelle est la taille du rÃ©sultat.

```python
s2 = s1 + chr(128520)
print(f"taille de la chaine python (RAM) : {sys.getsizeof(s2)} octets")
# 4080 avec Python version == 3.11
# 4064 avec Python version == 3.12
```

On constate que sa taille est maintenant de 4000 octets, plus quelques octets pour les mÃ©tadonnÃ©es.
Sa taille en mÃ©moire a donc quadruplÃ© en ajoutant un seul caractÃ¨reÂ !
Bingo, câ€™est lâ€™effet de lâ€™encodage Ã  largeur fixeÂ !
Si un caractÃ¨re de la chaine est codÃ© sur 4Â octets, alors tous les autres le seront aussi.
On constate aussi que la taille des mÃ©tadonnÃ©es a lÃ©gÃ¨rement augmentÃ© car les caractÃ¨res seuls prennent 1001Â Ã—Â 4Â =Â 4004Â octets.
Ã€ noter Ã©galement quâ€™en Python, les chaines sont immuables (_immutables_ en anglais).
Ce nâ€™est donc pas la chaine initiale qui a quadruplÃ© de taille, mais une copie modifiÃ©e de celle-ci.

Regardons maintenant ce qui se passe si on convertit notre nouvelle chaine en UTF-8 et quâ€™on mesure la taille du rÃ©sultat.

```python
s2u = s2.encode("utf-8")
print(f"taille de la chaine utf-8 (RAM)  : {sys.getsizeof(s2u)} octets")
# 1037 Python 3.11 et 3.12
```

```python
fname = "s2u.txt"
with open(file=fname, mode="wt", encoding="utf-8") as _f:
    _f.write(s2)
print(f"taille de la chaine utf-8 (HD)   : {os.path.getsize(fname)} octets")
# 1004 Python 3.11 et 3.12
```

**RÃ©sultat des courses, le rapport de taille entre la chaine Python et la chaine UTF-8 est donc deÂ 4Â !**

Si on refaisait lâ€™exercice en utilisant 1000Â Ã—Â `ğŸ˜ˆ` et 1Â Ã—Â `A`, on trouverait un rapport de taille deÂ 1 (en faisant abstraction des mÃ©tadonnÃ©es).

On constate Ã©galement quâ€™en UTF-8 la taille de s2 est 4Â octets plus grande que celle de s1.
Ceci est dÃ» au fait quâ€™UTF-8 enregistre les caractÃ¨res avec leur taille initiale, donc 1000Â Ã—Â 1Â octet pour le caractÃ¨reÂ `A` et 1Â Ã—Â 4Â octets pour le caractÃ¨re `ğŸ˜ˆ`.
Comme prÃ©cÃ©demment, la chaine en mÃ©moire prend quelques octets supplÃ©mentaires pour les mÃ©tadonnÃ©es.

Ã€ noter que je ne tiens pas compte des caractÃ¨res codÃ©s sur 2 et 3Â octets, mais le mÃªme raisonnement peut leur Ãªtre Ã©tendu.

En conclusion, le rapport entre la taille mÃ©moire utilisÃ©e par Python et la taille en UTF-8 peut varier dâ€™un facteur allant de 1 Ã Â 4.
Ces chiffres ne sont pas valables pour les trÃ¨s petites chaines Ã  cause de la taille des mÃ©tadonnÃ©es.
Par contre dÃ¨s que les chaines sont plus grandes, Ã§a fonctionne trÃ¨s bien.

Jâ€™ai mesurÃ© ce rapport sur une dizaine de fichiers contenant des livres entiers en franÃ§ais et je trouve un rapport moyen de 1.8.

## Les points de code

Pour comprendre, les chapitres suivants, il faut dâ€™abord comprendre ce quâ€™est un point de code.

Un â€œpoint de codeâ€ est un chiffre qui est attribuÃ© Ã  chaque caractÃ¨re de faÃ§on univoque.
Les points de code sont dÃ©finis par la norme Unicode et on peut les consulter dans la [table officielle des caractÃ¨res Unicode]
ou sur le site â€œ[table de caractÃ¨res Unicode]â€ (anciennement _unicode-table.com_).

[table officielle des caractÃ¨res Unicode]: https://www.unicode.org/charts/
[table de caractÃ¨res Unicode]: https://symbl.cc/fr/unicode/table/

> N.B. Lâ€™ancÃªtre dâ€™unicode est lâ€™ASCII.

## Calculer la taille dâ€™une chaine en Python

Pour calculer la taille totale utilisÃ©e par Python pour reprÃ©senter une chaine, il faut en premier trouver le caractÃ¨re de la chaine qui a le point de code le plus Ã©levÃ© puis utiliser la table ci-dessous pour dÃ©terminer le nombre dâ€™octets que Python utilisera pour stocker les caractÃ¨res de la chaine.
Ã€ noter que dÃ¨s que lâ€™on trouve un caractÃ¨re dont le point de code est supÃ©rieur Ã  65â€™535, on est sÃ»r que Python encodera la chaine sur 4Â octets.

|  Points<br>de code  | Nb dâ€™octets par<br>caractÃ¨re<br>(Python) | Encodage |
| :-----------------: | :--------------------------------------: | :------: |
|      0 .. 255       |                    1                     | Latin-1  |
|    256 .. 65â€™535    |                    2                     |  USC-2   |
| 65â€™536 .. 1â€™114â€™111 |                    4                     |  USC-4   |

Ensuite, il faut dÃ©terminer la taille des mÃ©tadonnÃ©es.
Elle dÃ©pend principalement de lâ€™encodage.
Ã€ noter que la taille des mÃ©tadonnÃ©es ne dÃ©pend pas du nombre de caractÃ¨res sauf pour quelques exceptions dÃ©taillÃ©es dans les tableaux ci-dessous.

**Nombre de caractÃ¨res dans la chaine == 0**

Lorsquâ€™une chaÃ®ne est vide, le nombre dâ€™octets par caractÃ¨re nâ€™est pas dÃ©fini (il est probablement supposÃ© Ã©tant Ã©gal Ã  1Â octet).
Ces valeurs resteront les mÃªmes pour les chaines contenant uniquement des points de codes infÃ©rieurs Ã  128.

| Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.11 | Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.12 |
| :----------------------------------------------: | :----------------------------------------------: |
|                        49                        |                        41                        |

**Nombre de caractÃ¨res dans la chaine == 1<br>et nb octet par caractÃ¨re == 2<br>et Python == 3.12**

Curieusement, en PythonÂ 3.12, si la chaine ne contient quâ€™un caractÃ¨re codÃ© sur deux octets, la taille de la chaine ne suit pas la relation Ã©noncÃ©e aprÃ¨s les tableaux.

En plus, une telle chaine prend au total 61Â octets alors quâ€™une chaine avec un caractÃ¨re de plus (toujours codÃ© sur 2Â octets) ne prendra que 59Â octets, soit deux octets de moins.

| Points<br>de code | Nb dâ€™octets par<br>caractÃ¨re | Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.12 |
| :---------------: | :--------------------------: | :----------------------------------------------: |
|   256 .. 65535    |              2               |                        59                        |

**Tous les autres cas**

| Points<br>de code  | Nb dâ€™octets par<br>caractÃ¨re | Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.11 | Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.12 |
| :----------------: | :--------------------------: | :----------------------------------------------: | :----------------------------------------------: |
|      0 .. 127      |              1               |                        49                        |                        41                        |
|     128 .. 255     |              1               |                        73                        |                        57                        |
|    256 .. 65535    |              2               |                        74                        |                        58                        |
| 65536 .. 1â€™114â€™111 |              4               |                        76                        |                        60                        |

Maintenant que nous connaissons la taille en octet de chaque caractÃ¨re et la taille des mÃ©tadonnÃ©es, nous pouvons calculer la taille en mÃ©moire de la chaine avec la relation suivanteÂ :

    T = N Ã— O + M

oÃ¹

-   T = Taille de la chaine en mÃ©moire
-   N = Nb total de caractÃ¨res
-   O = Nb dâ€™octets nÃ©cessaires pour le caractÃ¨re ayant le point de code le plus Ã©levÃ©
-   M = Nb dâ€™octets utilisÃ©s par les mÃ©tadonnÃ©es

> N.B. En Python, la valeur du point de code le plus grand possible peut Ãªtre obtenue avec la constante `sys.maxunicode`.
> Pour les versions conventionnelles de Python, elle vaut `1â€™114â€™111 = 2Â²â° + 2Â¹â¶ - 1`.
> Micropython nâ€™implÃ©mente pas la

## Calculer la taille dâ€™une chaine codÃ©e en UTF-8

En UTF-8, le calcul de la taille dâ€™une chaine est diffÃ©rent de celui utilisÃ© pour les chaines Python.
En effet, les caractÃ¨res sont enregistrÃ©s sur 1, 2, 3 ou 4Â octets et les plages des points de code ne sont pas exactement les mÃªmes.

|  Points<br>de code  | Nb dâ€™octets par<br>caractÃ¨re<br>(UTF-8) |
| :-----------------: | :-------------------------------------: |
|      0 .. 127       |                    1                    |
|     128 .. 2047     |                    2                    |
|   2048 .. 65â€™535    |                    3                    |
| 65â€™536 .. 1â€™114â€™111 |                    4                    |

Contrairement Ã  Python, en UTF-8 chaque caractÃ¨re conserve sa taille en octet, donc la taille de la chaine en mÃ©moire sera la suivanteÂ :

    T = Î£ Oi

oÃ¹

-   T = Taille de la chaine en mÃ©moire
-   Oi = Nb dâ€™octets nÃ©cessaire pour chaque caractÃ¨re individuel

> N.B. Par dÃ©faut, UTF-8 nâ€™utilise pas de mÃ©tadonnÃ©es.
> Cepandant, il existe une variante qui sâ€™appelle _UTF-8 with BOM_ _(Byte order mask)_ qui ajoute la sÃ©quence dâ€™octet `EF BB BF` au dÃ©but du fichier pour indiquer explicitement que le fichier est au format UTF-8.
> Ceci peut Ãªtre utile si on doit Ãªtre absolument sÃ»r du type de fichier par exemple sâ€™il est nÃ©cessaire de faire la distinction entre des fichiers UTF-8 et ASCII.
> En effet, un fichier UTF-8 qui ne contient que des caractÃ¨res dont les points de code sont infÃ©rieurs Ã  128 ne peut pas Ãªtre distinguÃ© dâ€™un fichier ASCII avec le mÃªme contenu.
> Ce sont les mÃªmes fichiers.
> Dâ€™oÃ¹ lâ€™intÃ©rÃªt de spÃ©cifier que lâ€™on souhaite que le fichier soit traitÃ© comme Ã©tant en UTF-8.
> Dans la pratique, le BOM est rarement utilisÃ© et peut apporter plus de problÃ¨mes que de solutions.
> Par contre, pour UTF-16 et UTF-32 le BOM est utile, mais Ã§a ne fait pas partie du cadre de cet article.

<!--

UCS

Universal Character Set

UCS2 : C'est un schÃ©ma de codage oÃ¹ chaque caractÃ¨re Unicode est reprÃ©sentÃ© sur 2 octets. Cela signifie qu'il peut reprÃ©senter des caractÃ¨res Unicode allant de U+0000 Ã  U+FFFF, soit 65 536 caractÃ¨res diffÃ©rents.

UCS4 : Ã€ l'inverse, UCS4 utilise 4 octets pour reprÃ©senter chaque caractÃ¨re Unicode. Cela permet de reprÃ©senter l'ensemble de l'espace Unicode, allant de U+0000 Ã  U+10FFFF, soit 1 114 112 caractÃ¨res diffÃ©rents.

-->

## ConsÃ©quences des diffÃ©rences dâ€™encodage

On lâ€™a vu, Python et UTF-8 sont passablement diffÃ©rents dans leur maniÃ¨re dâ€™encoder les chaines de caractÃ¨res.
Voici quelques consÃ©quences de ces diffÃ©rences.

-   On est obligÃ© de lire entiÃ¨rement une chaineÂ UTF-8 si lâ€™on veutÂ :

    -   ConnaÃ®tre la taille quâ€™elle prendra en mÃ©moire.
    -   ConnaÃ®tre le nombre de caractÃ¨res quâ€™elle contient.
    -   ConnaÃ®tre la position de tous les caractÃ¨res.

En effet, si une chaine est enregistrÃ©e dans un fichier qui prend 1000Â octets sur le disque, on ne peut pas savoir Ã  lâ€™avance sâ€™il contient 1000Â xÂ 1Â octets, 250Â Ã—Â 4Â octets ou nâ€™importe quelle autre combinaison avec des caractÃ¨res codÃ©s sur 2 ou 3Â octets.

-   Lâ€™accÃ¨s Ã  une position alÃ©atoire dans une chaineÂ UTF-8 est peu performant, puisquâ€™on ne connait la position dâ€™un caractÃ¨re quâ€™en lisant les caractÃ¨res qui le prÃ©cÃ¨de.
    Si cet aspect est important, on prÃ©fÃ¨rera utiliser UTF-32 qui enregistre tous les caractÃ¨res sur 4Â octets.

-   On ne peut pas calculer la taille en mÃ©moire vive en connaissant le nombre de caractÃ¨res codÃ©s sur 1, 2, 3 ou 4Â octets en UTF-8 parce que Python nâ€™utilise pas les mÃªmes tailles pour les mÃªmes points de code comme on lâ€™a vu dans les tableaux ci-dessus et sur la figure suivante.

```log
        0         127        255         2047        65535      1â€™114â€™111
Python  |_________1 B_________|__________2 B___________|____4 B____|
 UTF-8  |____1 B___|_ğŸ¤ª________2 B__________|____3 B_____|____4 B____|
```

## ...

```python
import numpy as np
fname = "./test_files/it.txt_part_0001.txt"
content = np.memmap(fname, dtype="uint8", mode="r")
byte_counters = {
    "1-B": np.count_nonzero(content >> 7 == 0b0),
    "2-B": np.count_nonzero(content >> 5 == 0b110),
    "3-B": np.count_nonzero(content >> 4 == 0b1110),
    "4-B": np.count_nonzero(content >> 3 == 0b11110),
}
print(byte_counters)
```

it.txt_part_0001_unicode_map.txt

<https://www.swisstransfer.com/d/815a168d-d818-4da3-9c83-462211c2f58d>

<https://data.statmt.org/cc-100/>

<https://data.statmt.org/cc-100/it.txt.xz>

<https://symbl.cc/en/unicode/table/>

<https://betterprogramming.pub/an-interviewers-favorite-question-how-are-python-strings-stored-in-internal-memory-ac0eaef9d9c2>

<https://rushter.com/blog/python-strings-and-memory/>

<!--


import sys

s1 = 1 * chr(181)
s2 = 2 * chr(181)
print(sys.getsizeof(s1), sys.getsizeof(s2))

# Python9  74 75
# Python10 74 75
# Python11 74 75
# Python12 61 59





Note that every string in Python takes additional 49-80 bytes of memory, where it stores supplementary information, such as hash, length, length in bytes, encoding type and string flags. That's why an empty string takes 49 bytes of memory.
 -->
