---
author: Nico
date: 2023-10-26 12:00:00+01:00
image:
    feature: null
lang: fr
layout: page
published: false
redirect_from: []
tags: []
title: Comment quadrupler la taille dâ€™une chaine en lui ajoutant un seul caractÃ¨reÂ ?
---

Dans cet article, nous allons dÃ©couvrir quelques subtilitÃ©s des chaines de caractÃ¨res en Python et en UTF-8.

ParticuliÃ¨rementÂ :

-   Quâ€™il est possible de quadrupler la mÃ©moire nÃ©cessaire Ã  une chaine en ne lui ajoutant quâ€™un seul caractÃ¨re.
-   Que cela est dÃ» au fait quâ€™en Python la taille des caractÃ¨res dâ€™une chaine est fixe, alors quâ€™UTF-8 utilise une taille de caractÃ¨res variable.
-   Quâ€™il est possible de compter super rapidement le nombre de caractÃ¨res en fonction de leur taille en octet dans une string codÃ©e en UTF-8.

> N.B.
> Dans cet article, quand il est fait mention de Python, il sâ€™agit toujours de PythonÂ 3, jamais de PythonÂ 2.

Les versions utilisÃ©es pour les tests sontÂ :

-   Python 3.11.6
-   Python 3.12.1

Lâ€™OS est macOS Sonoma 14.2.1 et les interprÃ©teurs Python ont Ã©tÃ© installÃ©s avec [Homebrew].

[Homebrew]: https://brew.sh/

## Calculer la taille dâ€™une chaine en mÃ©moire

## Calculer la taille dâ€™une chaine codÃ©e en UTF-8

## ConsÃ©quences des diffÃ©rences dâ€™encodage

## ...

Lâ€™idÃ©e mâ€™est venue dâ€™Ã©crire cet article suite Ã  [une question sur Stackoverflow] concernant la comparaison entre la taille dâ€™une chaine de caractÃ¨res en mÃ©moire avec Python avec sa taille quand elle est enregistrÃ©e dans un fichierÂ UTF-8.

[une question sur Stackoverflow]: https://stackoverflow.com/q/77310610/3057377

Lâ€™auteur sâ€™Ã©tonne que la taille en mÃ©moire soit 4Â fois plus grande que celle sur disque.
Mais est-ce si surprenantÂ ?
Voyons cela dâ€™un peu plus prÃ¨s.

Il faut dâ€™abord savoir que Python enregistre les chaines avec des caractÃ¨res codÃ©s sur 1, 2 ou 4Â octets, mais tous les caractÃ¨res dâ€™une mÃªme chaine doivent Ãªtre codÃ©s avec le mÃªme nombre dâ€™octets.
Câ€™est â€œlâ€™encodage Ã  taille fixeâ€ ou _â€œfixed-width encodingâ€_ en anglais.

En UTF-8, les choses sont un peu diffÃ©rentes, les chaines sont stockÃ©es sur 1, 2, 3 ou 4Â octets, mais il est possible dâ€™utiliser des caractÃ¨res codÃ©s avec des nombres diffÃ©rents dâ€™octets dans la mÃªme chaine.
Câ€™est â€œlâ€™encodage Ã  taille variableâ€, ou _â€œvariable-width encodingâ€_ en anglais.

Cette diffÃ©rence entre taille fixe et taille variable a une consÃ©quence intÃ©ressante.
Il est possible de quadrupler la taille dâ€™une chaine en mÃ©moire en lui ajoutant un seul caractÃ¨re.
Voici comment.

Tout dâ€™abord, crÃ©ons une chaine contenant 1000Â fois le mÃªme caractÃ¨re codÃ© sur 1Â octet, par exemple le caractÃ¨re `A` et regardons la taille du rÃ©sultat.

```python
import sys
s1 = "A" * 1000
print(sys.getsizeof(s1))
# 1049 avec Python version == 3.11
# 1041 avec Python version == 3.12
```

On voit que cette chaine fait un peu plus que 1000Â octets.
Les octets supplÃ©mentaires sont utilisÃ©s pour enregistrer des mÃ©tadonnÃ©es, mais laissons Ã§a de cÃ´tÃ© pour lâ€™instant.

Maintenant convertissons cette chaine en sa reprÃ©sentationÂ UTF-8.

```python
s1u = s1.encode("utf-8")
print(sys.getsizeof(s1u))
# 1033 Pour toutes les versions de Python
```

On constate que sa taille est dâ€™environ 1000Â octets.
Comme pour la chaine prÃ©cÃ©dente, Python ajoute quelques octets pour les mÃ©tadonnÃ©es.

Convertissons une deuxiÃ¨me fois cette chaÃ®ne, mais cette fois-ci en lâ€™enregistrant sur le disque.

```python
import os
fname = "s1u.txt"
with open(file=fname, mode="wt", encoding="utf-8") as _f:
    _f.write(s1)
os.path.getsize(fname)
# 1000 Pour toutes les versions de Python
```

On constate que sur le disque, la taille de cette chaÃ®ne au format UTF-8 est dâ€™exactement 1000Â octets.

Câ€™est maintenant que les choses deviennent intÃ©ressantes.
Ajoutons un caractÃ¨re codÃ© sur 4Â octets Ã  notre chaine initiale et regardons quelle est la taille du rÃ©sultat.

```python
s2 = s1 + "ğŸ˜ˆ"
print(sys.getsizeof(s2))
# 4080 avec Python version == 3.11
# 4064 avec Python version == 3.12
```

On constate que sa taille est maintenant de 4000 octets, plus quelques octets pour les mÃ©tadonnÃ©es.
Sa taille en mÃ©moire a donc quadruplÃ© en ajoutant un seul caractÃ¨reÂ !
Bingo, câ€™est lâ€™effet de lâ€™encodage Ã  largeur fixeÂ !
Si un caractÃ¨re de la chaine est codÃ© sur 4Â octets, alors tous les autres le seront aussi.
On constate aussi que la taille des mÃ©tadonnÃ©es a lÃ©gÃ¨rement augmentÃ© car les caractÃ¨res seuls prennent 1001Â Ã—Â 4Â =Â 4004Â octets.

Regardons maintenant ce qui se passe si on convertit notre nouvelle chaine en UTF-8 et quâ€™on mesure la taille du rÃ©sultat.

```python
s2u = s2.encode("utf-8")
print(sys.getsizeof(s2u))
# 1037
```

On constate quâ€™en UTF-8 la taille de s2 est 4Â octets plus grande que celle de s1.
Ceci est dÃ» au fait quâ€™UTF-8 enregistre les caractÃ¨res avec leur taille initiale, donc 1000Â Ã—Â 1Â octet pour le caractÃ¨reÂ `A` et 1Â Ã—Â 4Â octets pour le caractÃ¨re `ğŸ˜ˆ`.

Si on refaisait lâ€™exercice en utilisant 1000Â Ã—Â `ğŸ˜ˆ` et 1Â Ã—Â `A`, on trouverait un rapport de taille proche deÂ 1.

Ã€ noter que je ne tiens pas compte des caractÃ¨res codÃ©s sur 2 et 3Â octets, mais le mÃªme raisonnement peut facilement leur Ãªtre Ã©tendu.

En conclusion, le rapport entre la taille mÃ©moire utilisÃ©e par Python et la taille en UTF-8 peut varier dâ€™un facteur allant de 1 Ã Â 4.
Ces chiffres ne sont pas valables pour les trÃ¨s petites chaines Ã  cause de la taille des mÃ©tadonnÃ©es.
Par contre dÃ¨s que les chaines sont plus grandes, Ã§a fonctionne trÃ¨s bien.

Jâ€™ai mesurÃ© ce rapport sur une dizaine de fichiers contenant des livres entiers en franÃ§ais et je trouve un rapport moyen de 1.8.

## Calculer la taille dâ€™une chaine en mÃ©moire

<!--

Pour calculer la taille d


 -->

Nous avons vu quâ€™en Python, la taille dâ€™une chaine en mÃ©moire dÃ©pend trÃ¨s fortement des caractÃ¨res quâ€™elle contient et pas seulement de leur quantitÃ©.

Chaque caractÃ¨re est dÃ©fini par un nombre appelÃ© point de code.
On peut les consulter dans la [table officielle des caractÃ¨res Unicode]
ou sur le site â€œ[table de caractÃ¨res Unicode]â€ (anciennement _unicode-table.com_).

[table officielle des caractÃ¨res Unicode]: https://www.unicode.org/charts/
[table de caractÃ¨res Unicode]: https://symbl.cc/fr/unicode/table/

Pour calculer la taille totale utilisÃ©e par Python pour reprÃ©senter une chaine, il faut en premier trouver le caractÃ¨re de la chaine qui a le point de code le plus Ã©levÃ©.
Le nombre dâ€™octets utilisÃ©s par Python pour reprÃ©senter ce point de code sera utilisÃ© pour tous les autres points de code de la chaine.

**Taille en octets en fonction des points de code**

| Points<br>de code  | Nb dâ€™octets par<br>caractÃ¨re | Encodage |
| :----------------: | :--------------------------: | :------: |
|      0 .. 127      |              1               | Latin-1  |
|     128 .. 255     |              1               | Latin-1  |
|    256 .. 65535    |              2               |  USC-2   |
| 65536 .. 1â€™114â€™111 |              4               |  USC-4   |

Ensuite, il faut dÃ©terminer la taille des mÃ©tadonnÃ©es.
Elle dÃ©pend dÃ©pend principalement de la taille en octet du point de code le plus Ã©levÃ©.
Ã€ noter que la taille des mÃ©tadonnÃ©es ne dÃ©pend pas du nombre de caractÃ¨res sauf pour quelques exceptions dÃ©taillÃ©es dans les tableaux ci-dessous.

**Nombre de caractÃ¨res dans la chaine == 0**

Lorsquâ€™une chaÃ®ne est vide, le nombre dâ€™octets par caractÃ¨re nâ€™est pas dÃ©fini (il est probablement supposÃ© Ã©tant Ã©gal Ã  1Â octet).
Ces valeurs resteront les mÃªmes pour les chaines contenant uniquement des points de codes infÃ©rieurs Ã  128.

| Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.11 | Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.12 |
| :----------------------------------------------: | :----------------------------------------------: |
|                        49                        |                        41                        |

**Nombre de caractÃ¨res dans la chaine == 1<br>et nb octet par caractÃ¨re == 2<br>et Python == 3.12**

Curieusement, en PythonÂ 3.12, si la chaine ne contient quâ€™un caractÃ¨re codÃ© sur deux octets, la taille de la chaine ne suit pas la relation Ã©noncÃ©e aprÃ¨s les tableaux.

En plus, une telle chaine prend au total 61Â octets alors quâ€™une chaine avec un caractÃ¨re de plus (toujours codÃ© sur 2Â octets) ne prendra que 59Â octets, soit deux octets de moins.

| Points<br>de code | Nb dâ€™octets par<br>caractÃ¨re | Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.12 |
| :---------------: | :--------------------------: | :----------------------------------------------: |
|   256 .. 65535    |              2               |                        59                        |

**Tous les autres cas**

| Points<br>de code  | Nb dâ€™octets par<br>caractÃ¨re | Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.11 | Nb dâ€™octets<br>des mÃ©tadonnÃ©es<br>Python == 3.12 |
| :----------------: | :--------------------------: | :----------------------------------------------: | :----------------------------------------------: |
|      0 .. 127      |              1               |                        49                        |                        41                        |
|     128 .. 255     |              1               |                        73                        |                        57                        |
|    256 .. 65535    |              2               |                        74                        |                        58                        |
| 65536 .. 1â€™114â€™111 |              4               |                        76                        |                        60                        |

Maintenant que nous connaissons la taille en octet de chaque caractÃ¨re et la taille des mÃ©tadonnÃ©es, nous pouvons calculer la taille en mÃ©moire de la chaine avec la relation suivanteÂ :

    T = N Ã— O + M

oÃ¹

-   T = Taille de la chaine en mÃ©moire
-   N = Nb total de caractÃ¨res
-   O = Nb dâ€™octets nÃ©cessaires pour le caractÃ¨re ayant le point de code le plus Ã©levÃ©
-   M = Nb dâ€™octets utilisÃ©s par les mÃ©tadonnÃ©es

> N.B. En Python, la valeur du point de code le plus grand possible peut Ãªtre obtenue avec la constante `sys.maxunicode` et elle vaut `1â€™114â€™111 = 2Â²â° + 2Â¹â¶ - 1`.

## Calculer la taille dâ€™une chaine codÃ©e en UTF-8

En UTF-8, le calcul de la taille dâ€™une chaine est diffÃ©rent de celui utilisÃ© pour les chaines Python.
En effet, les caractÃ¨res sont enregistrÃ©s sur 1, 2, 3 ou 4Â octets et les plages des points de code ne sont pas exactement les mÃªmes.

| Points<br>de code  | Nb dâ€™octets<br>par caractÃ¨re |
| :----------------: | :--------------------------: |
|      0 .. 127      |              1               |
|    128 .. 2047     |              2               |
|   2048 .. 65535    |              3               |
| 65536 .. 1â€™114â€™111 |              4               |

Contrairement Ã  Python, en UTF-8 chaque caractÃ¨re conserve sa taille en octet, donc la taille de la chaine en mÃ©moire sera la suivanteÂ :

    T = Î£ Oi

oÃ¹

-   T = Taille de la chaine en mÃ©moire
-   Oi = Nb dâ€™octets nÃ©cessaire pour chaque caractÃ¨re individuel

> N.B. Par dÃ©faut, UTF-8 nâ€™utilise pas de mÃ©tadonnÃ©es.
> Cepandant, il existe une variante qui sâ€™appelle _UTF-8 with BOM_ _(Byte order mask)_ qui ajoute la sÃ©quence dâ€™octet `EF BB BF` au dÃ©but du fichier pour indiquer explicitement que le fichier est au format UTF-8.
> Ceci peut Ãªtre utile si on doit Ãªtre absolument sÃ»r du type de fichier par exemple sâ€™il est nÃ©cessaire de faire la distinction entre des fichiers UTF-8 et ASCII.
> En effet, un fichier UTF-8 qui ne contient que des caractÃ¨res dont les points de code sont infÃ©rieurs Ã  128 ne peut pas Ãªtre distinguÃ© dâ€™un fichier ASCII avec le mÃªme contenu.
> Ce sont les mÃªmes fichiers.
> Dâ€™oÃ¹ lâ€™intÃ©rÃªt de spÃ©cifier que lâ€™on souhaite que le fichier soit traitÃ© comme Ã©tant en UTF-8.
> Dans la pratique, le BOM est rarement utilisÃ© et peut apporter plus de problÃ¨mes que de solutions.
> Par contre, pour UTF-16 et UTF-32 le BOM est utile, mais Ã§a ne fait pas partie du cadre de cet article.

<!--

UCS

Universal Character Set

UCS2 : C'est un schÃ©ma de codage oÃ¹ chaque caractÃ¨re Unicode est reprÃ©sentÃ© sur 2 octets. Cela signifie qu'il peut reprÃ©senter des caractÃ¨res Unicode allant de U+0000 Ã  U+FFFF, soit 65 536 caractÃ¨res diffÃ©rents.

UCS4 : Ã€ l'inverse, UCS4 utilise 4 octets pour reprÃ©senter chaque caractÃ¨re Unicode. Cela permet de reprÃ©senter l'ensemble de l'espace Unicode, allant de U+0000 Ã  U+10FFFF, soit 1 114 112 caractÃ¨res diffÃ©rents.

-->

## ConsÃ©quences des diffÃ©rences dâ€™encodage

On lâ€™a vu, Python et UTF-8 sont passablement diffÃ©rents dans leur maniÃ¨re dâ€™encoder les chaines de caractÃ¨res.
Voici quelques consÃ©quences de ces diffÃ©rences.

-   On est obligÃ© de lire entiÃ¨rement une chaineÂ UTF-8 si lâ€™on veutÂ :

    -   ConnaÃ®tre la taille quâ€™elle prendra en mÃ©moire.
    -   ConnaÃ®tre le nombre de caractÃ¨res quâ€™elle contient.
    -   ConnaÃ®tre la position de tous les caractÃ¨res.

En effet, si une chaine est enregistrÃ©e dans un fichier qui prend 1000Â octets sur le disque, on ne peut pas savoir Ã  lâ€™avance sâ€™il contient 1000Â xÂ 1Â octets, 250Â Ã—Â 4Â octets ou nâ€™importe quelle autre combinaison avec des caractÃ¨res codÃ©s sur 2 ou 3Â octets.

-   Lâ€™accÃ¨s Ã  une position alÃ©atoire dans une chaineÂ UTF-8 est peu performant, puisquâ€™on ne connait la position dâ€™un caractÃ¨re quâ€™en lisant les caractÃ¨res qui le prÃ©cÃ¨de.
    Si cet aspect est important, on prÃ©fÃ¨rera utiliser UTF-32 qui enregistre tous les caractÃ¨res sur 4Â octets.

-   On ne peut pas calculer la taille en mÃ©moire vive en connaissant le nombre de caractÃ¨res codÃ©s sur 1, 2, 3 ou 4Â octets en UTF-8 parce que Python nâ€™utilise pas les mÃªmes tailles pour les mÃªmes points de code comme on lâ€™a vu dans les tableaux ci-dessus et sur la figure suivante.

```log
        0         127        255         2047        65535      1â€™114â€™111
Python  |____1 o____|____1 o____|________2 o___________|____4 o____|
 UTF-8  |____1 o____|__________2 o_________|____3 o____|____4 o____|
```

## ...

```python
import numpy as np
fname = "./test_files/it.txt_part_0001.txt"
content = np.memmap(fname, dtype="uint8", mode="r")
byte_counters = {
    "1-B": np.count_nonzero(content >> 7 == 0b0),
    "2-B": np.count_nonzero(content >> 5 == 0b110),
    "3-B": np.count_nonzero(content >> 4 == 0b1110),
    "4-B": np.count_nonzero(content >> 3 == 0b11110),
}
print(byte_counters)
```

it.txt_part_0001_unicode_map.txt

<https://www.swisstransfer.com/d/815a168d-d818-4da3-9c83-462211c2f58d>

<https://data.statmt.org/cc-100/>

<https://symbl.cc/en/unicode/table/>

<https://betterprogramming.pub/an-interviewers-favorite-question-how-are-python-strings-stored-in-internal-memory-ac0eaef9d9c2>

<https://data.statmt.org/cc-100/it.txt.xz>

<https://rushter.com/blog/python-strings-and-memory/>
