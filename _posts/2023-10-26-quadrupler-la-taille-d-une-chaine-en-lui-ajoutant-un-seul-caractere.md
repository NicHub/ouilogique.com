---
author: Nico
date: 2023-10-26 12:00:00+01:00
image:
    feature: null
lang: fr
layout: page
published: false
redirect_from: []
tags: []
title: Comment quadrupler la taille dâ€™une chaine en ne lui ajoutant quâ€™un seul caractÃ¨reÂ ?
---

Dans ce billet de blog, nous allons dÃ©couvrir quelques subtilitÃ©s des chaines de caractÃ¨res en Python et en UTF-8.
ParticuliÃ¨rementÂ :

-   Quâ€™il est possible de quadrupler la mÃ©moire nÃ©cessaire Ã  une chaine en ne lui ajoutant quâ€™un seul caractÃ¨re.
-   Les particularitÃ©s des encodages Ã  taille fixe variables.
-   Comment compter super rapidement le nombre de caractÃ¨res en fonction de leur taille en octet en UTF-8.

## Calculer la taille dâ€™une chaine en mÃ©moire

## Calculer la taille dâ€™une chaine codÃ©e en UTF-8

## ConsÃ©quences des diffÃ©rences dâ€™encodage

## ...

Lâ€™idÃ©e mâ€™est venue dâ€™Ã©crire ce billet suite Ã  une question sur Stackoverflow concernant le rapport entre la taille dâ€™une chaine en mÃ©moire avec Python comparÃ©e Ã  sa taille quand elle est enregistrÃ©e dans un fichierÂ UTF-8.

<https://stackoverflow.com/q/77310610/3057377>

Lâ€™auteur sâ€™Ã©tonne que la taille en mÃ©moire soit 4Â fois plus grande que celle sur disque.
Mais est-ce si surprenantÂ ?
Voyons cela dâ€™un peu plus prÃ¨s.

Il faut dâ€™abord savoir que Python enregistre les chaines avec des caractÃ¨res codÃ©s sur 1, 2 ou 4Â octets, mais tous les caractÃ¨res dâ€™une mÃªme chaine doivent Ãªtre codÃ©s avec le mÃªme nombre dâ€™octets. Câ€™est â€œlâ€™encodage Ã  taille fixeâ€ ou _â€œfixed-width encodingâ€_ en anglais.

En UTF-8, les choses sont un peu diffÃ©rentes, les chaines sont stockÃ©es sur 1, 2, 3 ou 4Â octets, mais il est possible dâ€™utiliser des caractÃ¨res codÃ©s avec des nombres diffÃ©rents dâ€™octets dans la mÃªme chaine. Câ€™est â€œlâ€™encodage Ã  taille variableâ€, ou _â€œvariable-width encodingâ€_ en anglais.

Cette diffÃ©rence entre taille fixe et taille variable a une consÃ©quence intÃ©ressante.
Il est possible de quadrupler la taille dâ€™une chaine en mÃ©moire en lui ajoutant un seul caractÃ¨re.
Voici comment.

Tout dâ€™abord, crÃ©ons une chaine contenant 1000Â fois un caractÃ¨re codÃ© sur 1Â octet, par exemple le caractÃ¨re `A` et regardons sa taille.

```python
import sys
s1 = "A" * 1000
print(sys.getsizeof(s1))
# 1049
```

On voit que cette chaine fait un peu plus que 1000Â octets.
Les 49Â octets supplÃ©mentaires sont utilisÃ©s pour enregistrer des mÃ©tadonnÃ©es, mais laissons Ã§a de cÃ´tÃ© pour lâ€™instant.

Maintenant convertissons cette chaine en sa reprÃ©sentationÂ UTF-8.

```python
s1u = s1.encode("utf-8")
print(sys.getsizeof(s1u))
# 1033
```

On constate que sa taille est dâ€™environ 1000Â octets.
Comme pour la chaine prÃ©cÃ©dente, Python ajoute quelques octets pour les mÃ©tadonnÃ©es.
Si on avait enregistrÃ© la chaine sur le disque, la taille du fichier aurait Ã©tÃ© dâ€™exactement 1000Â octets.

Câ€™est maintenant que les choses deviennent intÃ©ressantes.
Ajoutons un caractÃ¨re codÃ© sur 4Â octets Ã  notre chaine initiale et regardons quelle taille fait notre nouvelle chaine.

```python
s2 = s1 + "ğŸ˜ˆ"
print(sys.getsizeof(s2))
# 4080
```

On constate que sa taille est maintenant de 4080 octets.
Elle a donc quadruplÃ© en mÃ©moire en ajoutant un seul caractÃ¨reÂ !
Bingo, câ€™est lâ€™effet de lâ€™encodage Ã  largeur fixeÂ !
Si un caractÃ¨re de la chaine est codÃ© sur 4Â octets, alors tous les autres le seront aussi.
On constate aussi que la taille des mÃ©tadonnÃ©es a lÃ©gÃ¨rement augmentÃ© car les caractÃ¨res seuls prennent 1001Â Ã—Â 4Â =Â 4004Â octets.

Regardons maintenant ce qui se passe si on convertit notre nouvelle chaine en UTF-8 et quâ€™on mesure la taille du rÃ©sultat.

```python
s2u = s2.encode("utf-8")
print(sys.getsizeof(s2u))
# 1037
```

On constate quâ€™en UTF-8 la taille de s2 est 4Â octets plus grande que celle de s1.
Ceci est dÃ» au fait quâ€™UTF-8 enregistre les caractÃ¨res avec leur taille initiale, donc 1000Â Ã—Â 1Â octet pour le caractÃ¨reÂ `A` et 1Â Ã—Â 4Â octets pour le caractÃ¨re `ğŸ˜ˆ`.

Si on refaisait lâ€™exercice en utilisant 1000Â `ğŸ˜ˆ` et 1Â `A`, on trouverait un rapport de taille dâ€™environÂ 1.

Ã€ noter que je ne tiens pas compte des caractÃ¨res codÃ©s sur 2 et 3Â octets, mais le mÃªme raisonnement peut facilement leur Ãªtre Ã©tendu.

En conclusion, le rapport entre la taille mÃ©moire utilisÃ©e par Python et la taille en UTF-8 peut varier dâ€™un facteur allant de 1 Ã Â 4.
Ces chiffres ne sont pas valables pour les trÃ¨s petites chaines Ã  cause de la taille des mÃ©tadonnÃ©es.
Par contre dÃ¨s que les chaines sont plus grandes, Ã§a fonctionne trÃ¨s bien.

Jâ€™ai mesurÃ© ce rapport sur une dizaine de fichiers contenant des livres entiers en franÃ§ais et je trouve un rapport moyen de 1.8.

## Calculer la taille dâ€™une chaine en mÃ©moire

Nous avons vu quâ€™en Python, la taille dâ€™une chaine en mÃ©moire dÃ©pend trÃ¨s fortement des caractÃ¨res quâ€™elle contient et pas seulement de leur quantitÃ©.

Chaque caractÃ¨re est dÃ©fini par un nombre appelÃ© point de code.
On peut les consulter dans la [table officielle des caractÃ¨res Unicode]
ou sur <https://symbl.cc/en/unicode/table/>.

[table officielle des caractÃ¨res Unicode]: https://www.unicode.org/charts/

Connaissant le point de code le plus Ã©levÃ©, on peut savoir sur combien dâ€™octets Python codera tous les caractÃ¨res de la chaine en utilisant le tableau suivant.

| Points<br>de code  | Nb dâ€™octets par<br>caractÃ¨re | Nb dâ€™octets<br>des mÃ©tadonnÃ©es |
| :----------------: | :--------------------------: | :----------------------------: |
|      0 .. 127      |              1               |               49               |
|     128 .. 255     |              1               |               73               |
|    256 .. 65535    |              2               |               74               |
| 65536 .. 1â€™114â€™111 |              4               |               76               |

Et finalement il faudra appliquer la relation suivanteÂ :

    T = N Ã— O + M

oÃ¹

-   T = Taille de la chaine en mÃ©moire
-   N = Nb total de caractÃ¨re
-   O = Nb dâ€™octets nÃ©cessaires pour le caractÃ¨re ayant le point de code le plus Ã©levÃ©
-   M = Nb dâ€™octets utilisÃ©s par les mÃ©tadonnÃ©es

> N. B.
> En Python, la valeur du point de code le plus grand possible peut Ãªtre obtenue avec la constante `sys.maxunicode` et elle vaut 1â€™114â€™111 = 2Â²â° + 2Â¹â¶ - 1.

## Calculer la taille dâ€™une chaine codÃ©e en UTF-8

En UTF-8, le calcul de la taille dâ€™une chaine est diffÃ©rent de celui utilisÃ© pour les chaines Python.
En effet, les caractÃ¨res sont enregistrÃ©s sur 1, 2, 3 ou 4Â octets et les plages des points de code ne sont pas exactement les mÃªmes.

| Points<br>de code  | Nb dâ€™octets<br>par caractÃ¨re |
| :----------------: | :--------------------------: |
|      0 .. 127      |              1               |
|    128 .. 2047     |              2               |
|   2048 .. 65535    |              3               |
| 65536 .. 1â€™114â€™111 |              4               |

Contrairement Ã  Python, en UTF-8 chaque caractÃ¨re conserve sa taille en octet, donc la taille de la chaine en mÃ©moire sera la suivanteÂ :

    T = Î£ Oi

oÃ¹

-   T = Taille de la chaine en mÃ©moire
-   Oi = Nb dâ€™octets nÃ©cessaire par chaque caractÃ¨re individuel

## ConsÃ©quences des diffÃ©rences dâ€™encodage

On lâ€™a vu, Python et UTF-8 sont passablement diffÃ©rents dans leur maniÃ¨re dâ€™encoder les chaines de caractÃ¨re. Voici quelques consÃ©quences de ces diffÃ©rences.

-   On est obligÃ© de lire entiÃ¨rement une chaineÂ UTF-8 si lâ€™on veutÂ :

            -  ConnaÃ®tre la taille quâ€™elle prendra en mÃ©moire.
            -  ConnaÃ®tre le nombre de caractÃ¨res quâ€™elle contient.
            -  ConnaÃ®tre la position des caractÃ¨res.

En effet, si une chaine est enregistrÃ©e dans un fichier qui prend 1000Â octets sur le disque, on ne peut pas savoir Ã  lâ€™avance sâ€™il contient 1000Â xÂ 1Â octets, 250Â Ã—Â 4Â octets ou nâ€™importe quelle autre combinaison avec des caractÃ¨res codÃ©s sur 2 ou 3Â octets.

-   Lâ€™accÃ¨s Ã  une position alÃ©atoire dans une chaineÂ UTF-8 est peu performant, puisquâ€™on ne connait la position dâ€™un caractÃ¨re quâ€™en lisant les caractÃ¨res qui le prÃ©cÃ¨de.
    Si cet aspect est important, on prÃ©fÃ¨rera utiliser UTF-32 qui enregistre tous les caractÃ¨res sur 4Â octets.

-   On ne peut pas calculer la taille en mÃ©moire en connaissant le nombre de caractÃ¨res codÃ©s sur 1, 2, 3 ou 4Â octets en UTF-8 parce que Python nâ€™utilise pas les mÃªmes tailles pour les mÃªmes points de code comme on lâ€™a vu dans les tableaux ci-dessus et sur la figure suivante.

```log
        0         127        255      2047       65535    1â€™114â€™111
Python  |____1o____|____1o____|________2o__________|____4o____|
 UTF-8  |____1o____|_________2o_________|____3o____|____4o____|
```

## ...

```python
import numpy as np
fname = "./test_files/it.txt_part_0001.txt"
content = np.memmap(fname, dtype="uint8", mode="r")
byte_counters = {
    "1-B": np.count_nonzero(content >> 7 == 0b0),
    "2-B": np.count_nonzero(content >> 5 == 0b110),
    "3-B": np.count_nonzero(content >> 4 == 0b1110),
    "4-B": np.count_nonzero(content >> 3 == 0b11110),
}
print(byte_counters)
```

it.txt_part_0001_unicode_map.txt
https://www.swisstransfer.com/d/815a168d-d818-4da3-9c83-462211c2f58d

https://data.statmt.org/cc-100/

https://symbl.cc/en/unicode/table/


https://betterprogramming.pub/an-interviewers-favorite-question-how-are-python-strings-stored-in-internal-memory-ac0eaef9d9c2

https://data.statmt.org/cc-100/it.txt.xz
